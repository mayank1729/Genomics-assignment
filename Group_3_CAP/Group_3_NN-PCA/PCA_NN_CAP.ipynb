{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUp2OVqeLBrM"
   },
   "source": [
    "# Importing the librares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0EL8pelBLLt_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8M3QQzQrK4JY"
   },
   "source": [
    "# Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7-jNgcCEJRQn"
   },
   "outputs": [],
   "source": [
    "#dataset = pd.read_csv('X_trainData_1.csv')\n",
    "#labels=pd.read_csv('Y_trainData_1.csv')\n",
    "dataset = pd.read_csv('X_trainData_column_modified_PCA_CAP.csv')\n",
    "datalabels=pd.read_csv('X_trainData_column_modified_CAP.csv')\n",
    "\n",
    "\n",
    "X_train=dataset.iloc[:,:].values\n",
    "#X_train=dataset.iloc[:,:-1].values\n",
    "y_train=datalabels.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zb8TObA8vGuc"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "RDM-TheaftrR",
    "outputId": "d6f3a524-a70c-4e28-987f-30c2f447a7f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  1.07575094e+02 -1.90119808e+01 ...  1.67585513e-01\n",
      "  -1.60297759e-02 -2.52419486e-02]\n",
      " [ 2.00000000e+00  1.12747163e+02 -1.94524891e+01 ...  2.39257476e-01\n",
      "   7.85068934e-02 -3.99865137e-01]\n",
      " [ 3.00000000e+00  9.82537761e+01 -1.91011436e+01 ...  2.95889586e+00\n",
      "  -6.80896853e-01  2.05905530e-01]\n",
      " ...\n",
      " [ 1.33700000e+03  1.12481339e+02  4.59098368e+01 ... -7.63968245e-02\n",
      "  -3.91108815e-01 -3.47513066e-01]\n",
      " [ 1.33800000e+03  1.07273335e+02  4.20529961e+01 ... -1.24642162e+00\n",
      "  -6.49072096e-01  1.07213150e+00]\n",
      " [ 1.33900000e+03  1.12703974e+02  4.78657173e+01 ...  4.70730658e-02\n",
      "  -2.51965944e-01 -3.59163342e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "potB1vN5fxqI",
    "outputId": "13d88615-b3ca-46a0-e479-18949ee36f0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 1 1 1]\n",
      "752\n",
      "587\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "\n",
    "count1=0\n",
    "count0=0\n",
    "\n",
    "for n in y_train:\n",
    "  if n==1:\n",
    "    count1=count1+1\n",
    "  else:\n",
    "    count0=count0+1\n",
    "\n",
    "print(count1)\n",
    "print(count0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "un6aXeGQ-Bd2"
   },
   "source": [
    "# Building the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lIg2QwfU-GhZ",
    "outputId": "be750c8a-53df-4987-97e1-a961988e9950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8058\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.1728 - accuracy: 0.9388\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.9529\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0914 - accuracy: 0.9671\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.0859 - accuracy: 0.9731\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.9783\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9858\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9843\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0669 - accuracy: 0.9798\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0748 - accuracy: 0.9783\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9903\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9895\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9903\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9910\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 0.9940\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9843\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9881\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9903\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9918\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.9963\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9963\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9739\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9866\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9873\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 0.9948\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.9963\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9963\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9948\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9948\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9955\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9955\n",
      "Epoch 32/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9933\n",
      "Epoch 33/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.9955\n",
      "Epoch 34/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9978\n",
      "Epoch 35/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9963\n",
      "Epoch 36/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9970\n",
      "Epoch 37/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9978\n",
      "Epoch 38/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 0.9970\n",
      "Epoch 39/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.9978\n",
      "Epoch 40/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9978\n",
      "Epoch 41/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9963\n",
      "Epoch 42/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.9776\n",
      "Epoch 43/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9918\n",
      "Epoch 44/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.9955\n",
      "Epoch 45/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9963\n",
      "Epoch 46/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 0.9978\n",
      "Epoch 47/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.9948\n",
      "Epoch 48/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.9978\n",
      "Epoch 49/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9940\n",
      "Epoch 50/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9903\n",
      "Epoch 51/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9925\n",
      "Epoch 52/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9940\n",
      "Epoch 53/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9940\n",
      "Epoch 54/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 0.9963\n",
      "Epoch 55/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 0.9978\n",
      "Epoch 56/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 0.9978\n",
      "Epoch 57/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 0.9978\n",
      "Epoch 58/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9978\n",
      "Epoch 59/100\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.99 - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9978\n",
      "Epoch 60/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9978\n",
      "Epoch 61/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.9978\n",
      "Epoch 62/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9978\n",
      "Epoch 63/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9978\n",
      "Epoch 64/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.9978\n",
      "Epoch 65/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 0.9978\n",
      "Epoch 66/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0125 - accuracy: 0.9978\n",
      "Epoch 67/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.9970\n",
      "Epoch 68/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9970\n",
      "Epoch 69/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9978\n",
      "Epoch 70/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 0.9978\n",
      "Epoch 71/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9978\n",
      "Epoch 72/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9978\n",
      "Epoch 73/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9978\n",
      "Epoch 74/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 0.9978\n",
      "Epoch 75/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9978\n",
      "Epoch 76/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9978\n",
      "Epoch 77/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.9978\n",
      "Epoch 78/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 0.9978\n",
      "Epoch 79/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.9978\n",
      "Epoch 80/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.9978\n",
      "Epoch 81/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.9978\n",
      "Epoch 82/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9978\n",
      "Epoch 83/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.9978\n",
      "Epoch 84/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9978\n",
      "Epoch 85/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.9985\n",
      "Epoch 86/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9970\n",
      "Epoch 87/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9948\n",
      "Epoch 88/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9716\n",
      "Epoch 89/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 0.9716\n",
      "Epoch 90/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9903\n",
      "Epoch 91/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9948\n",
      "Epoch 92/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0124 - accuracy: 0.9970\n",
      "Epoch 93/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.9970\n",
      "Epoch 94/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.9978\n",
      "Epoch 95/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9978\n",
      "Epoch 96/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.9978\n",
      "Epoch 97/100\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9978\n",
      "Epoch 98/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9933\n",
      "Epoch 99/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 0.9963\n",
      "Epoch 100/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0b8c2f2430>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "\n",
    "#class_weight={1:1, 0:5}\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=12, activation='relu'))\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "ann.fit(X_train, y_train, batch_size = 16, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31FwZFBf4Vmk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "ude1J0E47SKN",
    "outputId": "225fcaf7-9f23-4542-c23e-eaa4034fab66"
   },
   "outputs": [],
   "source": [
    "#from xgboost import XGBClassifier\n",
    "#classifier = XGBClassifier()\n",
    "#classifier.fit(X_train, y_train)\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "#classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04CKLTr894tv"
   },
   "source": [
    "#Predicting Validation set results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "SoHWkVPH1s_O",
    "outputId": "f9bd9c68-135a-4b5a-a228-2b29ed89d728"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "501\n",
      "156\n",
      "[[ 1.00000000e+00  1.04826834e+02  4.12479709e+01 ... -1.66588102e+00\n",
      "   1.54536971e+00 -4.79476709e-01]\n",
      " [ 2.00000000e+00  1.09004854e+02  3.35838110e+01 ... -2.63355575e+00\n",
      "  -8.46839943e-01  1.31392004e+00]\n",
      " [ 3.00000000e+00  1.08294125e+02  4.06620371e+01 ... -9.06676587e-01\n",
      "   8.10714198e-01 -6.42887530e-01]\n",
      " ...\n",
      " [ 4.99000000e+02  1.11322786e+02  4.53693776e+01 ...  5.12968365e-01\n",
      "   6.96611427e-01  9.22126793e-01]\n",
      " [ 5.00000000e+02  1.10193302e+02  4.50443247e+01 ... -5.12303733e-01\n",
      "  -4.85042104e-01 -1.00620116e+00]\n",
      " [ 5.01000000e+02  1.11655703e+02  4.56392055e+01 ... -7.23516434e-01\n",
      "  -2.02709548e+00  1.35407658e+00]]\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('X_testData_column_modified_PCA_CAP.csv')\n",
    "#test_data = pd.read_csv('X_testData_1_modified.csv')\n",
    "\n",
    "X_test=test_data.iloc[:,:].values\n",
    "\n",
    "\n",
    "print(type(X_test))\n",
    "print(len(X_test))\n",
    "print(len(X_test[0]))\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3L4wXUSM987y",
    "outputId": "38c72dad-1283-4884-e9d2-9f8ab6ed2e0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99999887]\n",
      " [0.8763076 ]\n",
      " [0.99435306]\n",
      " [0.9214799 ]\n",
      " [0.9994937 ]\n",
      " [0.99382794]\n",
      " [0.9464716 ]\n",
      " [0.9922742 ]\n",
      " [0.9953058 ]\n",
      " [1.        ]\n",
      " [0.9928982 ]\n",
      " [0.99665904]\n",
      " [0.99240506]\n",
      " [0.8886399 ]\n",
      " [0.9895752 ]\n",
      " [0.5705273 ]\n",
      " [1.        ]\n",
      " [0.98157275]\n",
      " [0.999738  ]\n",
      " [1.        ]\n",
      " [0.99940264]\n",
      " [0.84772575]\n",
      " [0.99999964]\n",
      " [0.995265  ]\n",
      " [0.983675  ]\n",
      " [1.        ]\n",
      " [0.999354  ]\n",
      " [0.9963851 ]\n",
      " [0.9775785 ]\n",
      " [0.92963517]\n",
      " [1.        ]\n",
      " [0.9664117 ]\n",
      " [0.9974673 ]\n",
      " [0.9999977 ]\n",
      " [0.01622811]\n",
      " [0.9981275 ]\n",
      " [0.9735334 ]\n",
      " [1.        ]\n",
      " [0.9999659 ]\n",
      " [0.9954078 ]\n",
      " [0.9916289 ]\n",
      " [0.98625034]\n",
      " [0.98101115]\n",
      " [1.        ]\n",
      " [0.99999547]\n",
      " [0.998316  ]\n",
      " [0.9983307 ]\n",
      " [0.8702096 ]\n",
      " [0.93251145]\n",
      " [0.9999821 ]\n",
      " [0.99904084]\n",
      " [1.        ]\n",
      " [0.99850875]\n",
      " [1.        ]\n",
      " [0.9999873 ]\n",
      " [0.7220767 ]\n",
      " [1.        ]\n",
      " [0.99956656]\n",
      " [0.9338211 ]\n",
      " [1.        ]\n",
      " [0.98102224]\n",
      " [0.9996647 ]\n",
      " [0.999999  ]\n",
      " [0.99898237]\n",
      " [1.        ]\n",
      " [0.9922847 ]\n",
      " [0.99998426]\n",
      " [0.9972087 ]\n",
      " [0.949859  ]\n",
      " [0.96946424]\n",
      " [0.9979681 ]\n",
      " [0.9989834 ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9978564 ]\n",
      " [0.9934566 ]\n",
      " [0.9982075 ]\n",
      " [0.9978851 ]\n",
      " [0.99953675]\n",
      " [0.99994314]\n",
      " [0.99486667]\n",
      " [0.9955691 ]\n",
      " [1.        ]\n",
      " [0.99979866]\n",
      " [0.99407923]\n",
      " [0.99835974]\n",
      " [0.9978752 ]\n",
      " [0.9648293 ]\n",
      " [1.        ]\n",
      " [0.999939  ]\n",
      " [0.99928623]\n",
      " [0.99415517]\n",
      " [0.90231884]\n",
      " [0.95098037]\n",
      " [0.9651015 ]\n",
      " [0.8529315 ]\n",
      " [0.9926907 ]\n",
      " [0.8469075 ]\n",
      " [0.99999636]\n",
      " [1.        ]\n",
      " [0.99392897]\n",
      " [0.9997062 ]\n",
      " [0.98297626]\n",
      " [0.9812306 ]\n",
      " [0.9917811 ]\n",
      " [0.99996066]\n",
      " [0.99631095]\n",
      " [0.9999962 ]\n",
      " [0.9985277 ]\n",
      " [0.99998385]\n",
      " [1.        ]\n",
      " [0.99338603]\n",
      " [0.99799204]\n",
      " [0.99394864]\n",
      " [0.9915258 ]\n",
      " [0.99913335]\n",
      " [0.9924178 ]\n",
      " [0.9998863 ]\n",
      " [0.99434865]\n",
      " [0.85741854]\n",
      " [0.06545135]\n",
      " [0.9999997 ]\n",
      " [0.9999988 ]\n",
      " [0.89637697]\n",
      " [1.        ]\n",
      " [0.99675107]\n",
      " [0.38592273]\n",
      " [0.9997062 ]\n",
      " [0.9813665 ]\n",
      " [0.58438766]\n",
      " [0.9967568 ]\n",
      " [1.        ]\n",
      " [0.9497015 ]\n",
      " [0.9811227 ]\n",
      " [0.9962701 ]\n",
      " [0.9961375 ]\n",
      " [0.9999994 ]\n",
      " [0.98788023]\n",
      " [1.        ]\n",
      " [0.9971911 ]\n",
      " [0.90045166]\n",
      " [1.        ]\n",
      " [0.99508   ]\n",
      " [0.9998889 ]\n",
      " [0.9994489 ]\n",
      " [0.98141193]\n",
      " [0.9984843 ]\n",
      " [0.99108315]\n",
      " [0.99917966]\n",
      " [0.9999433 ]\n",
      " [0.99894667]\n",
      " [0.99516314]\n",
      " [0.9998866 ]\n",
      " [0.99902   ]\n",
      " [0.9998894 ]\n",
      " [0.9999276 ]\n",
      " [1.        ]\n",
      " [0.9871524 ]\n",
      " [0.99160206]\n",
      " [0.9999529 ]\n",
      " [0.997264  ]\n",
      " [0.99832076]\n",
      " [0.99899924]\n",
      " [1.        ]\n",
      " [0.9955845 ]\n",
      " [0.92158115]\n",
      " [0.9999368 ]\n",
      " [0.9994808 ]\n",
      " [0.9999949 ]\n",
      " [0.9980619 ]\n",
      " [0.97087014]\n",
      " [0.9977039 ]\n",
      " [0.998701  ]\n",
      " [0.9953059 ]\n",
      " [0.95626956]\n",
      " [0.98687315]\n",
      " [0.97746664]\n",
      " [0.6406605 ]\n",
      " [1.        ]\n",
      " [0.9996879 ]\n",
      " [0.9999989 ]\n",
      " [1.        ]\n",
      " [0.99999774]\n",
      " [0.99995244]\n",
      " [0.99748915]\n",
      " [0.97525465]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [0.9999418 ]\n",
      " [0.99677503]\n",
      " [0.9748119 ]\n",
      " [0.99798304]\n",
      " [0.98874444]\n",
      " [0.9885074 ]\n",
      " [0.9999816 ]\n",
      " [0.9520191 ]\n",
      " [0.99451315]\n",
      " [0.976694  ]\n",
      " [0.98720753]\n",
      " [0.98302454]\n",
      " [0.97569174]\n",
      " [0.99701965]\n",
      " [0.91728556]\n",
      " [0.9999192 ]\n",
      " [0.99939406]\n",
      " [0.99870074]\n",
      " [1.        ]\n",
      " [0.5393329 ]\n",
      " [0.9996488 ]\n",
      " [0.99991876]\n",
      " [0.9999256 ]\n",
      " [0.70241064]\n",
      " [0.9998908 ]\n",
      " [0.99872905]\n",
      " [0.9896504 ]\n",
      " [0.9965303 ]\n",
      " [0.95231676]\n",
      " [0.9798775 ]\n",
      " [0.9987769 ]\n",
      " [0.9991002 ]\n",
      " [0.9951081 ]\n",
      " [0.9993135 ]\n",
      " [0.96195674]\n",
      " [0.9982468 ]\n",
      " [0.99429214]\n",
      " [0.9973564 ]\n",
      " [0.9814309 ]\n",
      " [0.99431264]\n",
      " [0.9980239 ]\n",
      " [0.9605404 ]\n",
      " [0.93518233]\n",
      " [0.5841399 ]\n",
      " [0.9999971 ]\n",
      " [0.99459136]\n",
      " [0.9999709 ]\n",
      " [0.9791337 ]\n",
      " [0.99952817]\n",
      " [0.9676795 ]\n",
      " [0.9994015 ]\n",
      " [0.00432408]\n",
      " [0.9937302 ]\n",
      " [0.9981915 ]\n",
      " [0.994951  ]\n",
      " [0.99999774]\n",
      " [0.99796385]\n",
      " [0.9918523 ]\n",
      " [0.9965408 ]\n",
      " [0.9963726 ]\n",
      " [0.99996245]\n",
      " [0.9925007 ]\n",
      " [0.9890816 ]\n",
      " [0.9998282 ]\n",
      " [0.98741984]\n",
      " [0.98373693]\n",
      " [0.99983513]\n",
      " [0.99953055]\n",
      " [1.        ]\n",
      " [0.9997635 ]\n",
      " [0.99702156]\n",
      " [0.99611264]\n",
      " [0.9900203 ]\n",
      " [0.9972116 ]\n",
      " [0.99999636]\n",
      " [0.9996835 ]\n",
      " [0.99976957]\n",
      " [0.99963176]\n",
      " [0.9999012 ]\n",
      " [0.9998977 ]\n",
      " [0.99903095]\n",
      " [0.9987117 ]\n",
      " [0.99986327]\n",
      " [0.6905531 ]\n",
      " [0.984059  ]\n",
      " [0.98942375]\n",
      " [0.999966  ]\n",
      " [0.97832304]\n",
      " [0.9981783 ]\n",
      " [0.9982301 ]\n",
      " [0.99452996]\n",
      " [0.9848256 ]\n",
      " [0.00411153]\n",
      " [0.99852085]\n",
      " [0.9993239 ]\n",
      " [0.9068679 ]\n",
      " [0.9798907 ]\n",
      " [0.99972343]\n",
      " [0.9415176 ]\n",
      " [0.9007975 ]\n",
      " [0.9999552 ]\n",
      " [0.9989747 ]\n",
      " [0.9974    ]\n",
      " [0.9922061 ]\n",
      " [0.9924141 ]\n",
      " [0.92913795]\n",
      " [0.95891774]\n",
      " [0.9958842 ]\n",
      " [0.9189977 ]\n",
      " [1.        ]\n",
      " [0.94450176]\n",
      " [0.9977368 ]\n",
      " [0.9786029 ]\n",
      " [0.9945815 ]\n",
      " [0.96421105]\n",
      " [0.9920949 ]\n",
      " [0.9545189 ]\n",
      " [0.96525836]\n",
      " [0.99584436]\n",
      " [0.99993145]\n",
      " [0.9976419 ]\n",
      " [0.93301547]\n",
      " [0.99943084]\n",
      " [0.9710093 ]\n",
      " [0.9875839 ]\n",
      " [0.9530063 ]\n",
      " [0.9894647 ]\n",
      " [0.99999905]\n",
      " [0.9940182 ]\n",
      " [0.99637705]\n",
      " [0.9997358 ]\n",
      " [0.9736774 ]\n",
      " [0.98248816]\n",
      " [0.9651097 ]\n",
      " [0.9978119 ]\n",
      " [0.9898716 ]\n",
      " [0.93908453]\n",
      " [0.99996   ]\n",
      " [0.9988568 ]\n",
      " [0.9770828 ]\n",
      " [0.9989222 ]\n",
      " [0.9782146 ]\n",
      " [0.99046016]\n",
      " [0.9992297 ]\n",
      " [0.9878768 ]\n",
      " [0.997187  ]\n",
      " [0.84878933]\n",
      " [1.        ]\n",
      " [0.98712087]\n",
      " [0.91422534]\n",
      " [0.98740786]\n",
      " [0.98301387]\n",
      " [0.9898993 ]\n",
      " [0.9940485 ]\n",
      " [0.99729335]\n",
      " [0.977522  ]\n",
      " [0.99430764]\n",
      " [0.99394023]\n",
      " [0.9856424 ]\n",
      " [0.9729891 ]\n",
      " [0.9525149 ]\n",
      " [0.9508525 ]\n",
      " [0.99407625]\n",
      " [0.98075753]\n",
      " [0.98980147]\n",
      " [0.96589035]\n",
      " [0.982968  ]\n",
      " [0.96816343]\n",
      " [0.9921255 ]\n",
      " [0.4949939 ]\n",
      " [0.9981905 ]\n",
      " [0.9567873 ]\n",
      " [0.96947294]\n",
      " [0.92347664]\n",
      " [0.9935536 ]\n",
      " [0.9531747 ]\n",
      " [0.9380168 ]\n",
      " [0.9382298 ]\n",
      " [0.88965416]\n",
      " [0.92035234]\n",
      " [0.9790025 ]\n",
      " [0.9872388 ]\n",
      " [0.9810567 ]\n",
      " [0.97793317]\n",
      " [0.9397024 ]\n",
      " [0.9761265 ]\n",
      " [0.940117  ]\n",
      " [0.94032335]\n",
      " [0.99972254]\n",
      " [0.94073397]\n",
      " [0.99644727]\n",
      " [0.8986541 ]\n",
      " [0.5882784 ]\n",
      " [0.96576667]\n",
      " [0.81431997]\n",
      " [0.9403231 ]\n",
      " [0.9741515 ]\n",
      " [0.98499155]\n",
      " [0.9425446 ]\n",
      " [0.9285717 ]\n",
      " [0.9964683 ]\n",
      " [0.9962763 ]\n",
      " [0.9933537 ]\n",
      " [0.99392354]\n",
      " [0.99996924]\n",
      " [0.97873586]\n",
      " [0.9660268 ]\n",
      " [0.9443801 ]\n",
      " [0.99297583]\n",
      " [0.994267  ]\n",
      " [0.99292284]\n",
      " [0.9453824 ]\n",
      " [0.9678244 ]\n",
      " [0.97369206]\n",
      " [0.9461447 ]\n",
      " [0.99732304]\n",
      " [0.9859236 ]\n",
      " [0.98956794]\n",
      " [0.9707277 ]\n",
      " [0.98620594]\n",
      " [0.97346485]\n",
      " [0.99189365]\n",
      " [0.98178065]\n",
      " [0.96542233]\n",
      " [0.989651  ]\n",
      " [0.9135865 ]\n",
      " [0.7257074 ]\n",
      " [0.98706126]\n",
      " [0.987638  ]\n",
      " [0.9901142 ]\n",
      " [0.9911843 ]\n",
      " [0.98907626]\n",
      " [0.9937041 ]\n",
      " [0.9905352 ]\n",
      " [0.8851502 ]\n",
      " [0.91602993]\n",
      " [0.993189  ]\n",
      " [0.9969419 ]\n",
      " [0.9689181 ]\n",
      " [0.9929201 ]\n",
      " [0.95501685]\n",
      " [0.9698191 ]\n",
      " [0.9556399 ]\n",
      " [0.9880333 ]\n",
      " [0.9954856 ]\n",
      " [0.9973562 ]\n",
      " [0.9964394 ]\n",
      " [0.94357455]\n",
      " [0.9438704 ]\n",
      " [0.95091397]\n",
      " [0.9922595 ]\n",
      " [0.9905343 ]\n",
      " [0.99803185]\n",
      " [0.9270792 ]\n",
      " [0.95944023]\n",
      " [0.9597718 ]\n",
      " [0.9816859 ]\n",
      " [0.996686  ]\n",
      " [0.9893435 ]\n",
      " [0.9610723 ]\n",
      " [0.96139103]\n",
      " [0.93364626]\n",
      " [0.9896737 ]\n",
      " [0.9623325 ]\n",
      " [0.99794006]\n",
      " [0.9595243 ]\n",
      " [0.8879994 ]\n",
      " [0.96194774]\n",
      " [0.99843943]\n",
      " [0.9990953 ]\n",
      " [0.99747777]\n",
      " [0.86986494]\n",
      " [0.99975324]\n",
      " [0.99810743]\n",
      " [0.9974462 ]\n",
      " [0.99653184]\n",
      " [0.98633426]\n",
      " [0.96651816]\n",
      " [0.80422825]\n",
      " [0.99855983]\n",
      " [0.9956765 ]\n",
      " [0.97925854]\n",
      " [0.9978232 ]\n",
      " [0.98964643]\n",
      " [0.9950189 ]\n",
      " [0.86836106]\n",
      " [0.99444366]\n",
      " [0.863452  ]\n",
      " [0.95313764]\n",
      " [0.99814624]\n",
      " [0.8644862 ]\n",
      " [0.99570477]\n",
      " [0.9921733 ]\n",
      " [0.995752  ]\n",
      " [0.99643403]\n",
      " [0.9995285 ]\n",
      " [0.9681058 ]\n",
      " [0.99170864]\n",
      " [0.9585639 ]\n",
      " [0.828928  ]\n",
      " [0.99931073]\n",
      " [0.9387982 ]\n",
      " [0.9866892 ]\n",
      " [0.989836  ]\n",
      " [0.9401595 ]\n",
      " [0.9981593 ]\n",
      " [0.9939693 ]\n",
      " [0.96080005]\n",
      " [0.99868584]\n",
      " [0.997897  ]\n",
      " [0.99641633]\n",
      " [0.9974282 ]\n",
      " [0.9873036 ]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#y_pred = classifier.predict_proba(X_test)\n",
    "#y_pred = classifier.predict(X_test)\n",
    "y_pred = ann.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "print(type(y_pred))\n",
    "#y_pred = (y_pred > 0.5)\n",
    "#print(np.concatenate((y_pred.reshape(len(y_pred),1), y_validation.reshape(len(y_validation),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "h-VlhXT5075B",
    "outputId": "b474822e-4b1a-416d-87a1-e2d2f0751941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "QgwFIpIhCPlq",
    "outputId": "a132ba05-e7f9-4522-a0e4-5dd4f9f02429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ID', 'CAP'], [1, 0.99999887], [2, 0.8763076], [3, 0.99435306], [4, 0.9214799], [5, 0.9994937], [6, 0.99382794], [7, 0.9464716], [8, 0.9922742], [9, 0.9953058], [10, 1.0], [11, 0.9928982], [12, 0.99665904], [13, 0.99240506], [14, 0.8886399], [15, 0.9895752], [16, 0.5705273], [17, 1.0], [18, 0.98157275], [19, 0.999738], [20, 1.0], [21, 0.99940264], [22, 0.84772575], [23, 0.99999964], [24, 0.995265], [25, 0.983675], [26, 1.0], [27, 0.999354], [28, 0.9963851], [29, 0.9775785], [30, 0.92963517], [31, 1.0], [32, 0.9664117], [33, 0.9974673], [34, 0.9999977], [35, 0.01622811], [36, 0.9981275], [37, 0.9735334], [38, 1.0], [39, 0.9999659], [40, 0.9954078], [41, 0.9916289], [42, 0.98625034], [43, 0.98101115], [44, 1.0], [45, 0.99999547], [46, 0.998316], [47, 0.9983307], [48, 0.8702096], [49, 0.93251145], [50, 0.9999821], [51, 0.99904084], [52, 1.0], [53, 0.99850875], [54, 1.0], [55, 0.9999873], [56, 0.7220767], [57, 1.0], [58, 0.99956656], [59, 0.9338211], [60, 1.0], [61, 0.98102224], [62, 0.9996647], [63, 0.999999], [64, 0.99898237], [65, 1.0], [66, 0.9922847], [67, 0.99998426], [68, 0.9972087], [69, 0.949859], [70, 0.96946424], [71, 0.9979681], [72, 0.9989834], [73, 1.0], [74, 1.0], [75, 0.9978564], [76, 0.9934566], [77, 0.9982075], [78, 0.9978851], [79, 0.99953675], [80, 0.99994314], [81, 0.99486667], [82, 0.9955691], [83, 1.0], [84, 0.99979866], [85, 0.99407923], [86, 0.99835974], [87, 0.9978752], [88, 0.9648293], [89, 1.0], [90, 0.999939], [91, 0.99928623], [92, 0.99415517], [93, 0.90231884], [94, 0.95098037], [95, 0.9651015], [96, 0.8529315], [97, 0.9926907], [98, 0.8469075], [99, 0.99999636], [100, 1.0], [101, 0.99392897], [102, 0.9997062], [103, 0.98297626], [104, 0.9812306], [105, 0.9917811], [106, 0.99996066], [107, 0.99631095], [108, 0.9999962], [109, 0.9985277], [110, 0.99998385], [111, 1.0], [112, 0.99338603], [113, 0.99799204], [114, 0.99394864], [115, 0.9915258], [116, 0.99913335], [117, 0.9924178], [118, 0.9998863], [119, 0.99434865], [120, 0.85741854], [121, 0.065451354], [122, 0.9999997], [123, 0.9999988], [124, 0.89637697], [125, 1.0], [126, 0.99675107], [127, 0.38592273], [128, 0.9997062], [129, 0.9813665], [130, 0.58438766], [131, 0.9967568], [132, 1.0], [133, 0.9497015], [134, 0.9811227], [135, 0.9962701], [136, 0.9961375], [137, 0.9999994], [138, 0.98788023], [139, 1.0], [140, 0.9971911], [141, 0.90045166], [142, 1.0], [143, 0.99508], [144, 0.9998889], [145, 0.9994489], [146, 0.98141193], [147, 0.9984843], [148, 0.99108315], [149, 0.99917966], [150, 0.9999433], [151, 0.99894667], [152, 0.99516314], [153, 0.9998866], [154, 0.99902], [155, 0.9998894], [156, 0.9999276], [157, 1.0], [158, 0.9871524], [159, 0.99160206], [160, 0.9999529], [161, 0.997264], [162, 0.99832076], [163, 0.99899924], [164, 1.0], [165, 0.9955845], [166, 0.92158115], [167, 0.9999368], [168, 0.9994808], [169, 0.9999949], [170, 0.9980619], [171, 0.97087014], [172, 0.9977039], [173, 0.998701], [174, 0.9953059], [175, 0.95626956], [176, 0.98687315], [177, 0.97746664], [178, 0.6406605], [179, 1.0], [180, 0.9996879], [181, 0.9999989], [182, 1.0], [183, 0.99999774], [184, 0.99995244], [185, 0.99748915], [186, 0.97525465], [187, 1.0], [188, 1.0], [189, 0.9999418], [190, 0.99677503], [191, 0.9748119], [192, 0.99798304], [193, 0.98874444], [194, 0.9885074], [195, 0.9999816], [196, 0.9520191], [197, 0.99451315], [198, 0.976694], [200, 0.98720753], [202, 0.98302454], [204, 0.97569174], [206, 0.99701965], [208, 0.91728556], [212, 0.9999192], [213, 0.99939406], [215, 0.99870074], [216, 1.0], [217, 0.5393329], [218, 0.9996488], [219, 0.99991876], [220, 0.9999256], [221, 0.70241064], [222, 0.9998908], [224, 0.99872905], [227, 0.9896504], [228, 0.9965303], [231, 0.95231676], [232, 0.9798775], [234, 0.9987769], [235, 0.9991002], [236, 0.9951081], [238, 0.9993135], [239, 0.96195674], [240, 0.9982468], [242, 0.99429214], [243, 0.9973564], [244, 0.9814309], [245, 0.99431264], [247, 0.9980239], [251, 0.9605404], [256, 0.93518233], [257, 0.5841399], [258, 0.9999971], [259, 0.99459136], [262, 0.9999709], [263, 0.9791337], [264, 0.99952817], [266, 0.9676795], [267, 0.9994015], [270, 0.0043240786], [271, 0.9937302], [272, 0.9981915], [278, 0.994951], [279, 0.99999774], [280, 0.99796385], [281, 0.9918523], [287, 0.9965408], [289, 0.9963726], [290, 0.99996245], [296, 0.9925007], [302, 0.9890816], [307, 0.9998282], [316, 0.98741984], [319, 0.98373693], [320, 0.99983513], [325, 0.99953055], [333, 1.0], [345, 0.9997635], [352, 0.99702156], [356, 0.99611264], [363, 0.9900203], [380, 0.9972116], [381, 0.99999636], [388, 0.9996835], [392, 0.99976957], [398, 0.99963176], [413, 0.9999012], [422, 0.9998977], [431, 0.99903095], [455, 0.9987117], [467, 0.99986327], [483, 0.6905531], [485, 0.984059], [488, 0.98942375], [498, 0.999966], [503, 0.97832304], [510, 0.9981783], [524, 0.9982301], [543, 0.99452996], [549, 0.9848256], [554, 0.0041115284], [559, 0.99852085], [565, 0.9993239], [567, 0.9068679], [576, 0.9798907], [579, 0.99972343], [588, 0.9415176], [598, 0.9007975], [599, 0.9999552], [601, 0.9989747], [603, 0.9974], [628, 0.9922061], [631, 0.9924141], [632, 0.92913795], [633, 0.95891774], [634, 0.9958842], [635, 0.9189977], [636, 1.0], [637, 0.94450176], [638, 0.9977368], [639, 0.9786029], [640, 0.9945815], [641, 0.96421105], [642, 0.9920949], [643, 0.9545189], [644, 0.96525836], [645, 0.99584436], [646, 0.99993145], [647, 0.9976419], [648, 0.93301547], [649, 0.99943084], [650, 0.9710093], [651, 0.9875839], [652, 0.9530063], [653, 0.9894647], [654, 0.99999905], [655, 0.9940182], [656, 0.99637705], [657, 0.9997358], [658, 0.9736774], [659, 0.98248816], [660, 0.9651097], [661, 0.9978119], [662, 0.9898716], [663, 0.93908453], [664, 0.99996], [665, 0.9988568], [666, 0.9770828], [667, 0.9989222], [668, 0.9782146], [669, 0.99046016], [670, 0.9992297], [671, 0.9878768], [672, 0.997187], [673, 0.84878933], [674, 1.0], [675, 0.98712087], [676, 0.91422534], [677, 0.98740786], [678, 0.98301387], [679, 0.9898993], [680, 0.9940485], [681, 0.99729335], [682, 0.977522], [683, 0.99430764], [684, 0.99394023], [685, 0.9856424], [686, 0.9729891], [687, 0.9525149], [688, 0.9508525], [689, 0.99407625], [692, 0.98075753], [693, 0.98980147], [694, 0.96589035], [695, 0.982968], [696, 0.96816343], [697, 0.9921255], [698, 0.4949939], [699, 0.9981905], [700, 0.9567873], [701, 0.96947294], [702, 0.92347664], [703, 0.9935536], [704, 0.9531747], [705, 0.9380168], [706, 0.9382298], [707, 0.88965416], [708, 0.92035234], [709, 0.9790025], [710, 0.9872388], [711, 0.9810567], [712, 0.97793317], [713, 0.9397024], [714, 0.9761265], [715, 0.940117], [716, 0.94032335], [717, 0.99972254], [718, 0.94073397], [719, 0.99644727], [720, 0.8986541], [721, 0.5882784], [722, 0.96576667], [723, 0.81431997], [724, 0.9403231], [725, 0.9741515], [726, 0.98499155], [727, 0.9425446], [728, 0.9285717], [729, 0.9964683], [730, 0.9962763], [731, 0.9933537], [732, 0.99392354], [733, 0.99996924], [734, 0.97873586], [735, 0.9660268], [736, 0.9443801], [737, 0.99297583], [738, 0.994267], [739, 0.99292284], [740, 0.9453824], [741, 0.9678244], [742, 0.97369206], [743, 0.9461447], [744, 0.99732304], [745, 0.9859236], [746, 0.98956794], [747, 0.9707277], [748, 0.98620594], [749, 0.97346485], [750, 0.99189365], [751, 0.98178065], [752, 0.96542233], [753, 0.989651], [754, 0.9135865], [755, 0.7257074], [756, 0.98706126], [757, 0.987638], [758, 0.9901142], [759, 0.9911843], [760, 0.98907626], [761, 0.9937041], [762, 0.9905352], [763, 0.8851502], [764, 0.91602993], [765, 0.993189], [766, 0.9969419], [767, 0.9689181], [768, 0.9929201], [769, 0.95501685], [770, 0.9698191], [771, 0.9556399], [772, 0.9880333], [773, 0.9954856], [774, 0.9973562], [775, 0.9964394], [776, 0.94357455], [777, 0.9438704], [778, 0.95091397], [779, 0.9922595], [780, 0.9905343], [781, 0.99803185], [782, 0.9270792], [783, 0.95944023], [784, 0.9597718], [785, 0.9816859], [786, 0.996686], [787, 0.9893435], [788, 0.9610723], [789, 0.96139103], [790, 0.93364626], [791, 0.9896737], [792, 0.9623325], [805, 0.99794006], [809, 0.9595243], [816, 0.8879994], [826, 0.96194774], [841, 0.99843943], [847, 0.9990953], [893, 0.99747777], [951, 0.86986494], [952, 0.99975324], [953, 0.99810743], [954, 0.9974462], [955, 0.99653184], [956, 0.98633426], [957, 0.96651816], [958, 0.80422825], [959, 0.99855983], [960, 0.9956765], [961, 0.97925854], [962, 0.9978232], [963, 0.98964643], [964, 0.9950189], [965, 0.86836106], [966, 0.99444366], [967, 0.863452], [968, 0.95313764], [969, 0.99814624], [970, 0.8644862], [971, 0.99570477], [972, 0.9921733], [973, 0.995752], [974, 0.99643403], [975, 0.9995285], [976, 0.9681058], [977, 0.99170864], [978, 0.9585639], [979, 0.828928], [980, 0.99931073], [981, 0.9387982], [982, 0.9866892], [983, 0.989836], [984, 0.9401595], [985, 0.9981593], [986, 0.9939693], [987, 0.96080005], [988, 0.99868584], [989, 0.997897], [990, 0.99641633], [991, 0.9974282], [992, 0.9873036]]\n"
     ]
    }
   ],
   "source": [
    "submission_data = pd.read_csv('Y_testData_1_nolabels_CAP.csv')\n",
    "\n",
    "ids=submission_data.iloc[:,:1].values\n",
    "result=list()\n",
    "k=0\n",
    "#print(ids)\n",
    "#print(y_pred[0])\n",
    "for i in ids:\n",
    "  #result.append([ i[0], y_pred[i[0]-1][0] ])\n",
    "  #result.append([ i[0], y_pred[i[0]-1][0] ])\n",
    "  result.append([ i[0], y_pred[k][0] ])\n",
    "  #result.append([ i[0], y_pred[k][1] ])\n",
    "  k=k+1\n",
    "  #print(y_pred[i[0]-1][0])\n",
    "  #print('.')\n",
    "\n",
    "result.insert(0, ['ID','CAP'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Q1zP-sxYFP46"
   },
   "outputs": [],
   "source": [
    "file = open('CAP_result.csv', 'w+', newline ='') \n",
    "  \n",
    "# writing the data into the file \n",
    "with file:     \n",
    "    write = csv.writer(file) \n",
    "    write.writerows(result) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aa-vi0QM-LC9"
   },
   "source": [
    "# Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cw5t7mVa-Phl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYyn2oDE3JmY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCCFSasG3XYt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FE37sSMdzp-n"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PCA-NN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
